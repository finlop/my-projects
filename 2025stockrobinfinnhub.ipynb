{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2d7cd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification workflow required. Please check your Robinhood app for instructions.\n",
      "Waiting for challenge to be validated\n",
      "5.067613840103149\n",
      "Waiting for challenge to be validated\n",
      "10.154067039489746\n",
      "Waiting for challenge to be validated\n",
      "15.225662469863892\n",
      "‚úÖ Token saved to robinhood_token.txt\n"
     ]
    }
   ],
   "source": [
    "from robinhood_auth_login import login\n",
    "\n",
    "# Perform login\n",
    "login_response = login(\n",
    "    username=\"nandarohan442@gmail.com\",\n",
    "    password=\"Ron1506313015$\",\n",
    "    by_sms=True,\n",
    "    store_session=False\n",
    ")\n",
    "\n",
    "# Save token to file\n",
    "with open(\"robinhood_token.txt\", \"w\") as f:\n",
    "    f.write(login_response[\"access_token\"])\n",
    "\n",
    "print(\"‚úÖ Token saved to robinhood_token.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e84ac8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock data saved to my_stock_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os  \n",
    "\n",
    "# Load token from file\n",
    "def load_token_from_file(file_path=\"robinhood_token.txt\"):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            return f.read().strip()\n",
    "    return None\n",
    "\n",
    "# Fetch and save stock data\n",
    "def fetch_and_save_stock_data(token, output_file=\"my_stock_data.xlsx\"):\n",
    "    url = \"https://api.robinhood.com/positions/\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error fetching stock data:\", response.text)\n",
    "        return\n",
    "\n",
    "    positions = response.json().get(\"results\", [])\n",
    "    stock_data = []\n",
    "\n",
    "    # Get the current timestamp\n",
    "    fetch_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    for position in positions:\n",
    "        if float(position[\"quantity\"]) > 0:  # Only fetch open positions\n",
    "            instrument_url = position[\"instrument\"]\n",
    "            instrument_data = requests.get(instrument_url, headers=headers).json()\n",
    "\n",
    "            symbol = instrument_data[\"symbol\"]\n",
    "            quantity = float(position[\"quantity\"])\n",
    "            average_buy_price = float(position[\"average_buy_price\"])\n",
    "            quote_url = f\"https://api.robinhood.com/quotes/{symbol}/\"\n",
    "            current_price = float(requests.get(quote_url, headers=headers).json()[\"last_trade_price\"])\n",
    "\n",
    "            market_value = current_price * quantity\n",
    "            profit_loss = (current_price - average_buy_price) * quantity\n",
    "\n",
    "            stock_data.append({\n",
    "                \"Timestamp\": fetch_time,  # Add the timestamp\n",
    "                \"Symbol\": symbol,\n",
    "                \"Quantity\": quantity,\n",
    "                \"Average Buy Price\": average_buy_price,\n",
    "                \"Current Price\": current_price,\n",
    "                \"Market Value\": market_value,\n",
    "                \"Profit/Loss\": profit_loss\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(stock_data)\n",
    "    df.to_excel(output_file, index=False)\n",
    "    print(f\"Stock data saved to {output_file}\")\n",
    "\n",
    "# Use token to fetch data\n",
    "token = load_token_from_file()\n",
    "if token:\n",
    "    fetch_and_save_stock_data(token)\n",
    "else:\n",
    "    print(\"No token found. Please log in first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19a54e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:14:10] üì• Gathering tradable stock tickers...\n",
      "[19:15:38] üîç Filtering 37 tickers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 37/37 [00:37<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:16:16] üì¶ Data saved to filtered_tickers.db\n",
      "[19:16:16] ‚úÖ Done. 2569 valid tickers, 2918 rejected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "# --- CONFIG ---\n",
    "RATE_LIMIT_DELAY = 1\n",
    "MAX_WORKERS = 4\n",
    "MIN_VOLUME = 100000\n",
    "MIN_DOLLAR_VOLUME = 1_000_000\n",
    "MAX_STDDEV = 0.05\n",
    "MIN_PRICE = 3.0\n",
    "MOMENTUM_LOOKBACK_DAYS = 5\n",
    "SAVE_INTERVAL = 50\n",
    "TOKEN_FILE = \"robinhood_token.txt\"\n",
    "CHECKPOINT_FILE = \"checkpoint_filtered.csv\"\n",
    "REJECTED_FILE = \"checkpoint_rejected.csv\"\n",
    "DB_FILE = \"filtered_tickers.db\"\n",
    "RETRY_FAILED_ONLY = False\n",
    "FINNHUB_API_KEY = \"YOUR_API_KEY\"  # Replace with your actual Finnhub API key\n",
    "\n",
    "# --- TOKEN ---\n",
    "def load_token_from_file(file_path=TOKEN_FILE):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            return f.read().strip()\n",
    "    return None\n",
    "\n",
    "token = load_token_from_file()\n",
    "HEADERS = {\"Authorization\": f\"Bearer {token}\"} if token else {}\n",
    "\n",
    "# --- LOGGING ---\n",
    "def log(msg):\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] {msg}\")\n",
    "\n",
    "# --- SAFE REQUEST ---\n",
    "def safe_request(url, max_retries=3, delay=2):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            r = requests.get(url, headers=HEADERS)\n",
    "            if r.status_code == 429:\n",
    "                log(f\"‚è≥ Rate limited. Sleeping {delay * (attempt + 1)}s...\")\n",
    "                time.sleep(delay * (attempt + 1))\n",
    "                continue\n",
    "            r.raise_for_status()\n",
    "            return r\n",
    "        except Exception as e:\n",
    "            log(f\"‚ö†Ô∏è Error on request to {url}: {e}\")\n",
    "            time.sleep(delay * (attempt + 1))\n",
    "    return None\n",
    "\n",
    "# --- HISTORICAL DATA ---\n",
    "def get_history(ticker):\n",
    "    url = f\"https://api.robinhood.com/quotes/historicals/{ticker}/?interval=day&span=week\"\n",
    "    r = safe_request(url)\n",
    "    if r:\n",
    "        data = r.json().get(\"historicals\", [])\n",
    "        closes = [float(d[\"close_price\"]) for d in data if d[\"close_price\"] != \"0.0000\"]\n",
    "        volumes = [int(d[\"volume\"]) for d in data]\n",
    "        return closes, volumes\n",
    "    return [], []\n",
    "\n",
    "# --- QUOTE CHECK ---\n",
    "def is_valid_quote(ticker):\n",
    "    url = f\"https://api.robinhood.com/quotes/{ticker}/\"\n",
    "    r = safe_request(url)\n",
    "    if r and r.status_code == 200:\n",
    "        data = r.json()\n",
    "        return data.get(\"last_trade_price\") is not None\n",
    "    return False\n",
    "\n",
    "# --- FINNHUB FUNDAMENTALS ---\n",
    "def get_sector(symbol):\n",
    "    try:\n",
    "        url = f\"https://finnhub.io/api/v1/stock/profile2?symbol={symbol}&token={FINNHUB_API_KEY}\"\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 200:\n",
    "            return r.json().get(\"finnhubIndustry\", \"Unknown\")\n",
    "    except:\n",
    "        pass\n",
    "    return \"Unknown\"\n",
    "\n",
    "def get_fundamentals(symbol):\n",
    "    try:\n",
    "        url = f\"https://finnhub.io/api/v1/stock/metric?symbol={symbol}&metric=all&token={FINNHUB_API_KEY}\"\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 200:\n",
    "            metrics = r.json().get(\"metric\", {})\n",
    "            return {\n",
    "                \"PE\": metrics.get(\"peBasicExclExtraTTM\", None),\n",
    "                \"MarketCap\": metrics.get(\"marketCapitalization\", None),\n",
    "                \"DebtEquity\": metrics.get(\"totalDebt/totalEquityAnnual\", None)\n",
    "            }\n",
    "    except:\n",
    "        pass\n",
    "    return {\"PE\": None, \"MarketCap\": None, \"DebtEquity\": None}\n",
    "\n",
    "# --- FILTERING LOGIC ---\n",
    "def check_liquidity(closes, volumes):\n",
    "    if len(closes) < 3 or sum(volumes) == 0:\n",
    "        return False\n",
    "    avg_vol = sum(volumes) / len(volumes)\n",
    "    avg_dollar_vol = sum(c * v for c, v in zip(closes, volumes)) / len(closes)\n",
    "    return avg_vol >= MIN_VOLUME and avg_dollar_vol >= MIN_DOLLAR_VOLUME\n",
    "\n",
    "def check_volatility(closes):\n",
    "    returns = pd.Series(closes).pct_change().dropna()\n",
    "    return returns.std() <= MAX_STDDEV\n",
    "\n",
    "def check_price(closes):\n",
    "    return closes[-1] >= MIN_PRICE\n",
    "\n",
    "def check_momentum(closes):\n",
    "    return len(closes) > MOMENTUM_LOOKBACK_DAYS and closes[-1] > closes[-MOMENTUM_LOOKBACK_DAYS]\n",
    "\n",
    "# --- PROCESS TICKER ---\n",
    "def process_ticker(item):\n",
    "    ticker = item[\"symbol\"]\n",
    "    name = item.get(\"name\", \"\")\n",
    "\n",
    "    try:\n",
    "        if not is_valid_quote(ticker):\n",
    "            return None, {\"Ticker\": ticker, \"Reason\": \"Invalid quote\"}\n",
    "\n",
    "        closes, volumes = get_history(ticker)\n",
    "        if not closes or not volumes:\n",
    "            return None, {\"Ticker\": ticker, \"Reason\": \"No history\"}\n",
    "\n",
    "        if not check_price(closes):\n",
    "            return None, {\"Ticker\": ticker, \"Reason\": \"Price < $3\"}\n",
    "\n",
    "        if not check_liquidity(closes, volumes):\n",
    "            return None, {\"Ticker\": ticker, \"Reason\": \"Liquidity fail\"}\n",
    "\n",
    "        if not check_volatility(closes):\n",
    "            return None, {\"Ticker\": ticker, \"Reason\": \"Volatility fail\"}\n",
    "\n",
    "        if not check_momentum(closes):\n",
    "            return None, {\"Ticker\": ticker, \"Reason\": \"No uptrend\"}\n",
    "\n",
    "        sector = get_sector(ticker)\n",
    "        fundamentals = get_fundamentals(ticker)\n",
    "\n",
    "        log(f\"‚úÖ {ticker} passed all filters.\")\n",
    "        return {\n",
    "            \"Ticker\": ticker,\n",
    "            \"Name\": name,\n",
    "            \"Sector\": sector,\n",
    "            \"Price\": closes[-1],\n",
    "            \"PE\": fundamentals[\"PE\"],\n",
    "            \"MarketCap\": fundamentals[\"MarketCap\"],\n",
    "            \"DebtEquity\": fundamentals[\"DebtEquity\"]\n",
    "        }, None\n",
    "    except Exception as e:\n",
    "        log(f\"‚ùå Error processing {ticker}: {e}\")\n",
    "        return None, {\"Ticker\": ticker, \"Reason\": \"Processing exception\"}\n",
    "\n",
    "# --- SAVE TO SQLITE ---\n",
    "def save_to_sqlite(data, db_path=DB_FILE):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_sql(\"FilteredTickers\", conn, if_exists=\"replace\", index=False)\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    log(f\"üì¶ Data saved to {db_path}\")\n",
    "\n",
    "# --- CHECKPOINT ---\n",
    "def save_checkpoint(data, path):\n",
    "    temp_path = tempfile.mktemp()\n",
    "    pd.DataFrame(data).to_csv(temp_path, index=False)\n",
    "    os.replace(temp_path, path)\n",
    "\n",
    "# --- MAIN ---\n",
    "def main():\n",
    "    final_filtered = pd.read_csv(CHECKPOINT_FILE).to_dict('records') if os.path.exists(CHECKPOINT_FILE) else []\n",
    "    rejected_tickers = pd.read_csv(REJECTED_FILE).to_dict('records') if os.path.exists(REJECTED_FILE) else []\n",
    "    already_processed = set(d['Ticker'] for d in final_filtered + rejected_tickers)\n",
    "\n",
    "    if RETRY_FAILED_ONLY:\n",
    "        tickers_to_process = [{\"symbol\": t[\"Ticker\"], \"name\": \"\"} for t in rejected_tickers]\n",
    "        final_filtered = []\n",
    "        rejected_tickers = []\n",
    "        log(f\"üîÅ Retrying {len(tickers_to_process)} previously rejected tickers...\")\n",
    "    else:\n",
    "        url = \"https://api.robinhood.com/instruments/\"\n",
    "        next_url = url\n",
    "        tickers_to_process = []\n",
    "        log(\"üì• Gathering tradable stock tickers...\")\n",
    "\n",
    "        while next_url:\n",
    "            r = safe_request(next_url)\n",
    "            if not r:\n",
    "                break\n",
    "            data = r.json()\n",
    "            for item in data[\"results\"]:\n",
    "                if item[\"type\"] == \"stock\" and item[\"tradeable\"]:\n",
    "                    if item[\"symbol\"] not in already_processed:\n",
    "                        tickers_to_process.append({\"symbol\": item[\"symbol\"], \"name\": item[\"name\"]})\n",
    "            next_url = data.get(\"next\")\n",
    "\n",
    "    log(f\"üîç Filtering {len(tickers_to_process)} tickers...\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = {executor.submit(process_ticker, item): item[\"symbol\"] for item in tickers_to_process}\n",
    "        for idx, future in enumerate(tqdm(as_completed(futures), total=len(futures), desc=\"Processing\")):\n",
    "            ticker = futures[future]\n",
    "            try:\n",
    "                result, error = future.result()\n",
    "                if result:\n",
    "                    final_filtered.append(result)\n",
    "                elif error:\n",
    "                    rejected_tickers.append(error)\n",
    "            except Exception as e:\n",
    "                log(f\"‚ùå Future failed for {ticker}: {e}\")\n",
    "                rejected_tickers.append({\"Ticker\": ticker, \"Reason\": \"Unhandled exception\"})\n",
    "\n",
    "            if (len(final_filtered) + len(rejected_tickers)) % SAVE_INTERVAL == 0:\n",
    "                save_checkpoint(final_filtered, CHECKPOINT_FILE)\n",
    "                save_checkpoint(rejected_tickers, REJECTED_FILE)\n",
    "                log(f\"üíæ Checkpoint saved at {len(final_filtered)} valid, {len(rejected_tickers)} rejected.\")\n",
    "\n",
    "            time.sleep(RATE_LIMIT_DELAY)\n",
    "\n",
    "    save_to_sqlite(final_filtered)\n",
    "    log(f\"‚úÖ Done. {len(final_filtered)} valid tickers, {len(rejected_tickers)} rejected.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa8e876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0880b0de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4801b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4040ee3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969a5489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b2f5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
