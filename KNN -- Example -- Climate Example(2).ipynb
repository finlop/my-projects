{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a11099f",
   "metadata": {},
   "source": [
    "# Exercise 1 -- Earth Science dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ca0268",
   "metadata": {},
   "source": [
    "### 1.\tCreate a regression model to predict global average temperature based on CO2, N2O, and CH4. Uss KNN algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a5123",
   "metadata": {},
   "source": [
    "some steps are given to show how you can visulazie data to helo speed up the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a231ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 1500)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -- Extend cell width\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a288df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- load data\n",
    "\n",
    "data = pd.read_csv('C:/Users/mxp180004/Downloads/World_Climate.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21ff5a2",
   "metadata": {},
   "source": [
    "N2O, Global atmospheric nitrous oxide concentration\n",
    "Atmospheric nitrous oxide (N₂O) concentration is measured in parts per billion (ppb).\n",
    "\n",
    "Monthly sea surface temperature anomaly\n",
    "This is measured at a nominal depth of 20cm, and given relative to the average temperature from the period of 1961 - 1990.\n",
    "\n",
    "Sea Surface anomaly\n",
    "This is measured at a nominal depth of 20cm, and given relative to the average temperature from the period of 1961 - 1990.\n",
    "\n",
    "Temperature anomaly\n",
    "The monthly combined land-surface air and sea-surface water temperature anomaly is given as the deviation from the1951–1980 mean.\n",
    "\n",
    "\n",
    "CH4, Global atmospheric methane concentration\n",
    "Atmospheric methane (CH₄) concentration is measured in parts per billion (ppb).\n",
    "\n",
    "CO2, Global atmospheric CO₂ concentration\n",
    "Atmospheric carbon dioxide (CO₂) concentration is measured in parts per million (ppm).\n",
    "\n",
    "\n",
    "Sea level rise\n",
    "Global mean sea level rise is measured relative to the 1993 - 2008 average sea level. This is shown as three series: the widely-cited Church & White\n",
    "dataset; the University of Hawaii Sea Level Center (UHLSC); and the average of the two.\n",
    "\n",
    "Ocean acidification: mean seawater PH\n",
    "Mean seawater pH is shown based on in-situ measurements of pH from the Aloha station in Hawaii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5775ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9179393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9151485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# available data is shown in gray color and missing data points are in white for each column.\n",
    "import missingno as msno\n",
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a25164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# create data\n",
    "values=data['monthly_sea_surface_temperature_anomaly'].dropna()\n",
    "values.plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9e5e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want plot 2 or more in one graph\n",
    "value1 =data['CO2 Monthly averaged'].dropna()\n",
    "value2 =data['CO2 Annual averaged'].dropna()\n",
    "value12 = pd.concat([value1, value2], axis=1)\n",
    "value12.plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e223cb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -- heat map to see corrolation between features\n",
    "corrmat = data.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(30,30))\n",
    "\n",
    "# -- plot heat map\n",
    "sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\",) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9416a004",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data[['Date','Temperature anomaly','N2O Monthly averaged','CH4 Monthly averaged','CO2 Monthly averaged']].dropna()\n",
    "X=df[['CO2 Monthly averaged','N2O Monthly averaged','CH4 Monthly averaged']]\n",
    "y=df['Temperature anomaly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f09577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -- heat map to see corrolation between features\n",
    "corrmat = df.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# -- plot heat map\n",
    "sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\",) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ebacb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from copy import deepcopy\n",
    "\n",
    "cols_to_drop = []\n",
    "num_scalers = {}\n",
    "'''Scale only original columns'''\n",
    "for col in X:\n",
    " if pd.api.types.is_numeric_dtype(X[col].dtype):\n",
    "    print(\"MinMax scale of \", col)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X[[col]])\n",
    "    X[col+\"_sc\"] = scaler.transform(X[[col]])\n",
    "    \n",
    "    num_scalers[col] = [deepcopy(scaler),\"MinMax\"]\n",
    "    cols_to_drop.append(col)\n",
    "X=X.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23cf048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- split data \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75cbfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "%matplotlib inline\n",
    "train_score_array = []\n",
    "test_score_array = []\n",
    "\n",
    "for k in range(1,25):\n",
    "    knn_reg = KNeighborsRegressor(k)\n",
    "    knn_reg.fit(X_train, y_train)\n",
    "    train_score_array.append(knn_reg.score(X_train, y_train))\n",
    "    test_score_array.append(knn_reg.score(X_test, y_test))\n",
    "\n",
    "x_axis = range(1,25)\n",
    "plt.subplots(figsize = (20,5))\n",
    "plt.plot(x_axis, train_score_array, c = 'g', label = 'Train Score')\n",
    "plt.plot(x_axis, test_score_array, c = 'b', label = 'Test Score')\n",
    "plt.legend()\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e62ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "%matplotlib inline\n",
    "train_score_array = []\n",
    "test_score_array = []\n",
    "\n",
    "knn_reg = KNeighborsRegressor(6)\n",
    "knn_reg.fit(X_train, y_train)\n",
    "print('train score: ', knn_reg.score(X_train, y_train))\n",
    "print('test  score: ',knn_reg.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59130b44",
   "metadata": {},
   "source": [
    "### 2.\tIf the amount of CO2, N2O, and CH4 decrease gradually by 0.5%,0.1%, and 0.1% respectively every year for the next 15 years, what is the model prediction for reduction of the global average temperature in the next 15 years? Plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd7f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- load data\n",
    "\n",
    "data_future = pd.read_csv('C:/Users/mxp180004/Downloads/World_Future_Climate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cc0ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeb76b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "future=pd.DataFrame()\n",
    "future['N2O Annual averaged']=data_future['N2O']\n",
    "future['CH4 Annual averaged']=data_future['CH4']\n",
    "future['CO2 Annual averaged']=data_future['CO2']\n",
    "future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1b60b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from copy import deepcopy\n",
    "cols_to_drop = []\n",
    "num_scalers = {}\n",
    "'''Scale only original columns'''\n",
    "for col in future:\n",
    "  if pd.api.types.is_numeric_dtype(future[col].dtype):\n",
    "    print(\"MinMax scale of \", col)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(future[[col]])\n",
    "    future[col+\"_sc\"] = scaler.transform(future[[col]])\n",
    "    \n",
    "    num_scalers[col] = [deepcopy(scaler),\"MinMax\"]\n",
    "    cols_to_drop.append(col)\n",
    "future=future.drop(columns=cols_to_drop)\n",
    "future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87509e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = knn_reg.predict(future)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87458cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_future['Tempreture anomaly predict']=predict\n",
    "data_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b954df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix date columns\n",
    "\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data_future['date'] = pd.to_datetime(data_future['date'], format='%Y')\n",
    "\n",
    "# plot\n",
    "data_plot=data[['Date','Temperature anomaly']].dropna()\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30,10)) \n",
    "plt.plot('Date', 'Temperature anomaly', data=data_plot, linestyle='-', marker='o')\n",
    "plt.plot('date', 'Tempreture anomaly predict', data=data_future, linestyle='-', marker='o',color='mediumvioletred')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
