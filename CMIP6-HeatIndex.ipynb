{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caaa72f5",
   "metadata": {},
   "source": [
    "# Exercise 13: Compute local downscaled CMIP6 ensemble Heat Index\n",
    "\n",
    "Load needed packages.  Be sure they have been installed using \"conda install -c conda-forge packagename\".\n",
    "\n",
    "This Notebook is licensed for free and open consumption under the [Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)](https://creativecommons.org/licenses/by-nc/4.0/) license.\n",
    "\n",
    "CVS:  $Id: CMIP6-HeatIndex.ipynb,v 25.1 2025/04/16 17:04:53 brikowi Exp $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc6415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load needed packages\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request              # Manage URL's\n",
    "import numpy as np                 # Basic math and simple arrays\n",
    "import xarray as xr                # Better & faster multidimensional arrays\n",
    "import zarr                        # Chunked very fast cloud-based arrays\n",
    "from sklearn.linear_model import LinearRegression  # Use conda install -c conda-forge scikit-learn\n",
    "\n",
    "import pandas as pd                # Dataframes, similar to internal spreadsheet\n",
    "from difflib import get_close_matches\n",
    "import gcsfs                       # Google cloud filesystem routines\n",
    "import datetime\n",
    "import time                        # Get runtime data\n",
    "startTime = time.time()\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8379079",
   "metadata": {},
   "source": [
    "# Define functions to get desired variable from desired model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7081e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVar (modelList, modelName):\n",
    "    # Custom function to get variable for model 'modelName' from list of possible models 'modelList'\n",
    "    zstore = modelList.query(f\"source_id == '{modelName}'\").zstore.values[0]\n",
    "    ds = xr.open_zarr(zstore, consolidated = True)\n",
    "    ds.load()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5c0bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatIndex (T, RH):\n",
    "    # Compute heat index given temperature (T, Centrigrade) and relative humidity (RH, percent)\n",
    "    # Official Imperial units formula at https://www.wpc.ncep.noaa.gov/html/heatindex_equation.shtml\n",
    "    # N.B. skipping high-low range corrections for now.  Test at https://www.wpc.ncep.noaa.gov/html/heatindex.shtml\n",
    "    # Assign coefficients\n",
    "    c1, c2, c3, c4, c5, c6 = -42.379, 2.04901523, 10.14333127, -0.22475541, -6.83783e-3, -5.481717e-2\n",
    "    c7, c8, c9 = 1.22874e-3, 8.5282e-4, -1.99e-6\n",
    "    # Convert T to degF \n",
    "    F = T*9/5. + 32.0\n",
    "    \n",
    "    # Steadman approximation\n",
    "    HI = 0.5 * (F + 61.0 + (F-68.0)*1.2 + (RH*0.094))\n",
    "    \n",
    "    if (HI+F)/2 > 80.:\n",
    "        # Use full Rothfusz regression\n",
    "        HI = c1 + c2*F + c3*RH + c4*F*RH + c5*F**2 + c6*RH**2 + c7*F**2*RH + c8*F*RH**2 + c9*F**2*RH**2\n",
    "        # Apply adjustments if needed\n",
    "        if ((RH<13.0) & (F>80.) & (F<112.)):\n",
    "            HI = HI +  ((13-RH)/4) * sqrt((17-abs(F-95.))/17)\n",
    "        elif ((RH>85.) * (F>80.) & (F<87.)):\n",
    "                HI = HI + (RH-85)/10 * (87-F)/5\n",
    "\n",
    "    return HI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e0aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lat-long box, initially the DFW Metroplex\n",
    "pointLat = 32.7666\n",
    "pointLon = 360 - 96.7778"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d44224",
   "metadata": {},
   "source": [
    "# Get desired models available at Google\n",
    "Get file list from Google via the given URL, use Pandas (pd) to read the CSV file and save in a *dataframe* \"df\".  A Pandas dataframe is like a spreadsheet format for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242c002",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061e9807",
   "metadata": {},
   "source": [
    "## Get list of all available SSP3 7.0 models with *tasmax*\n",
    "Find lines in the file-list dataframe \"df\" that meet the given criteria, most important are that the variable *tasmax* is in the file and that it is from a model of experiment *ssp370* (the currently most-likely CO2 emissions scenario)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7150da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ssp370TAS = df.query(\"activity_id=='ScenarioMIP' & table_id == 'Amon' & \" +\\\n",
    "    \"variable_id == 'tas' & experiment_id == 'ssp370' & member_id == 'r1i1p1f1'\")\n",
    "print(len(df_ssp370TAS), 'forecast files match the search criteria, the first 3 are:')\n",
    "df_ssp370TAS.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081f7dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly relative humidity\n",
    "df_ssp370RH = df.query(\"activity_id=='ScenarioMIP' & table_id == 'Amon' & \" +\\\n",
    "    \"variable_id == 'hur' & experiment_id == 'ssp370' & member_id == 'r1i1p1f1'\")\n",
    "print(len(df_ssp370RH), 'forecast files match the search criteria, the first 3 are:')\n",
    "df_ssp370RH.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac22317d",
   "metadata": {},
   "source": [
    "## Get list of all historical models with *tas* and *RH* (hur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12582277",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historicalTAS = df.query(\"activity_id == 'CMIP' & table_id == 'Amon' & \" +\\\n",
    "    \"variable_id == 'tas' & experiment_id == 'historical' & member_id == 'r1i1p1f1'\")\n",
    "df_historicalRH = df.query(\"activity_id == 'CMIP' & table_id == 'Amon' & \" +\\\n",
    "    \"variable_id == 'hur' & experiment_id == 'historical' & member_id == 'r1i1p1f1'\")\n",
    "print(len(df_historicalTAS), 'historical files match the TAS search criteria.')\n",
    "print(len(df_historicalRH), 'historical files match the RH search criteria, the first 3 are:')\n",
    "df_historicalRH.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eb681d",
   "metadata": {},
   "source": [
    "## Make list of models with  historical and future tas and RH\n",
    "See <a href=\"https://stackoverflow.com/questions/55898796/how-to-match-keys-of-2-data-frames-and-create-new-df-with-matching-keys\">StackOverflow</a> for suggestions.  Current code requires start with shortest dataframe (!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07ad019",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASmatch = [r for r in df_ssp370TAS[\"source_id\"] if get_close_matches(r, df_historicalTAS[\"source_id\"], n=1, cutoff = .85)]\n",
    "hindForeTAS = np.unique(np.array(TASmatch))\n",
    "RHmatch = [r for r in df_ssp370RH[\"source_id\"] if get_close_matches(r, df_historicalRH[\"source_id\"], n=1, cutoff = .85)]\n",
    "hindForeRH = np.unique(np.array(RHmatch))\n",
    "hindForeTAS_RH = [r for r in hindForeTAS if get_close_matches(r, hindForeRH, n=1, cutoff = .85)]\n",
    "# print(len(hindForeTAS), \"models have both historical and SSP3-7.0 TAS results\")\n",
    "# print(len(hindForeRH), \"models have both historical and SSP3-7.0 RH results\")\n",
    "print(len(hindForeTAS_RH), \"models have historical and SSP3-7.0 TAS and RH results\")\n",
    "print(\"e.g. \", hindForeTAS_RH[3])\n",
    "\n",
    "gcs = gcsfs.GCSFileSystem(token='anon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9358d1",
   "metadata": {},
   "source": [
    "## Skip statistical downscaling\n",
    "PRISM does have gridded historical RH, based on \"climate-assisted\" modeling (PRISM-Historical)[https://prism.oregonstate.edu/historical/].  Might be questionable for downscaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d98de75",
   "metadata": {},
   "source": [
    "# Compute monthly heat index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2443b5",
   "metadata": {},
   "source": [
    "Compute monthly heat index for each hindcast and forecast model, assemble ensemble statistics of those.  Many of the 29 files require large RAM during download.  We'll limit ourselves to the 3 fastest-downloading models in the list *goodsources*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c640403d",
   "metadata": {},
   "source": [
    "## Get forecast tas & RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38693a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Revised from CMIPP6-HeatIndex.py v. 1.5\n",
    "foreTASfile = \"ssp370forecastTAS.csv\"\n",
    "foreRHfile = \"ssp370forecastRH.csv\"\n",
    "goodSources = ['NorESM2-MM', 'MPI-ESM1-2-LR', 'CanESM5']\n",
    "# goodSources = ['CanESM5']\n",
    "for i in range(len(goodSources)):\n",
    "    model = goodSources[i]\n",
    "    print(f\"Processing model: {model} TAS\", end='...', flush=True)\n",
    "    \n",
    "    # Get forecast TAS values for desired point\n",
    "    ds_TASfore = getVar(df_ssp370TAS, model)\n",
    "    pointTASfore = ds_TASfore.sel(lat=pointLat, lon=pointLon, method=\"nearest\").tas - 273.15 # Convert to Celsius\n",
    "    # Convert to dataframe, Drop unneeded columns\n",
    "    tempDF = pointTASfore.to_dataframe().drop(columns=[\"lat\", \"lon\", \"height\"])       \n",
    "    # Append TAS results to dataframe 'foreTAS'\n",
    "    if i==0:\n",
    "        foreTAS = tempDF\n",
    "        foreTAS.columns = [model]\n",
    "    else:\n",
    "        newTAS = tempDF['tas']           # Extract values, Assuming same time index for all files\n",
    "        foreTAS[model] = (newTAS.values)\n",
    "    # Delete large dataframe to save RAM\n",
    "    del tempDF\n",
    "    gc.collect()\n",
    "\n",
    "    # Save results to file each step in case of trouble\n",
    "    foreTAS.to_csv(foreTASfile)\n",
    "\n",
    "    # Repeat for relative humidity ('hur')\n",
    "    # Get infinte loop for some models (e.g. 'EC-Earth3') when try to download !?!\n",
    "    # Others succeed as expected (e.g. 'CanESM5').  Try timeout? \n",
    "    # see https://medium.com/@chaoren/how-to-timeout-in-python-726002bf2291\n",
    "    print(\"RH\", flush=True)\n",
    "    ds_RHfore = getVar(df_ssp370RH, model)\n",
    "    pointRHfore = ds_RHfore.sel(lat=pointLat, lon=pointLon, method=\"nearest\").hur\n",
    "    tempDF = pointRHfore.to_dataframe()\n",
    "    # N.B. tempDF indices are tuples [cftime, plev], plev is pressure level, 100000.0 Pa is surface\n",
    "    surfaceRH = tempDF.xs(100000.0, level=\"plev\").drop(columns=[\"lat\", \"lon\"]) # Extract surface RH\n",
    "    # Delete large dataframe and recover memory\n",
    "    del tempDF         \n",
    "    gc.collect()\n",
    "    # Append surface RH results to dataframe 'foreRH'\n",
    "    if i==0:\n",
    "        foreRH = surfaceRH\n",
    "        foreRH.columns = [model]\n",
    "    else:\n",
    "        newRH = surfaceRH['hur']           # Extract values, Assuming same time index for all files\n",
    "        foreRH[model] = (newRH.values)\n",
    "\n",
    "    # Save results to file each step in case of trouble\n",
    "    foreRH.to_csv(foreRHfile)\n",
    "    del surfaceRH         # Delete large dataframe and recover memory\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02223ce",
   "metadata": {},
   "source": [
    "## Get historical tas & RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c8a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Revised from CMIPP6-HeatIndex.py v. 1.5\n",
    "hindTASfile = \"ssp370hindcastTAS.csv\"\n",
    "hindRHfile = \"ssp370hindcastRH.csv\"\n",
    "\n",
    "for i in range(len(goodSources)):\n",
    "    model = goodSources[i]\n",
    "    print(f\"Processing model: {model} TAS\", end='...', flush=True)\n",
    "    \n",
    "    # Get hindcast TAS values for desired point\n",
    "    ds_TAShind = getVar(df_historicalTAS, model)\n",
    "    pointTAShind = ds_TAShind.sel(lat=pointLat, lon=pointLon, method=\"nearest\").tas - 273.15 # Convert to Celsius\n",
    "    # Convert to dataframe, Drop unneeded columns\n",
    "    tempDF = pointTAShind.to_dataframe().drop(columns=[\"lat\", \"lon\", \"height\"])       \n",
    "    # Append TAS results to dataframe 'hindTAS'\n",
    "    if i==0:\n",
    "        hindTAS = tempDF\n",
    "        hindTAS.columns = [model]\n",
    "    else:\n",
    "        newTAS = tempDF['tas']           # Extract values, Assuming same time index for all files\n",
    "        hindTAS[model] = (newTAS.values)\n",
    "    # Delete large dataframe to save RAM\n",
    "    del tempDF\n",
    "    gc.collect()\n",
    "\n",
    "    # Save results to file each step in case of trouble\n",
    "    hindTAS.to_csv(hindTASfile)\n",
    "\n",
    "    # Repeat for relative humidity ('hur')\n",
    "    # Get infinte loop for some models (e.g. 'EC-Earth3') when try to download !?!\n",
    "    # Others succeed as expected (e.g. 'CanESM5').  Try timeout? \n",
    "    # see https://medium.com/@chaoren/how-to-timeout-in-python-726002bf2291\n",
    "    print(\"RH\", flush=True)\n",
    "    ds_RHhind = getVar(df_historicalRH, model)\n",
    "    pointRHhind = ds_RHhind.sel(lat=pointLat, lon=pointLon, method=\"nearest\").hur\n",
    "    tempDF = pointRHhind.to_dataframe()\n",
    "    # N.B. tempDF indices are tuples [cftime, plev], plev is pressure level, 100000.0 Pa is surface\n",
    "    surfaceRH = tempDF.xs(100000.0, level=\"plev\").drop(columns=[\"lat\", \"lon\"]) # Extract surface RH\n",
    "    # Delete large dataframe and recover memory\n",
    "    del tempDF         \n",
    "    gc.collect()\n",
    "    # Append surface RH results to dataframe 'hindRH'\n",
    "    if i==0:\n",
    "        hindRH = surfaceRH\n",
    "        hindRH.columns = [model]\n",
    "    else:\n",
    "        newRH = surfaceRH['hur']           # Extract values, Assuming same time index for all files\n",
    "        hindRH[model] = (newRH.values)\n",
    "\n",
    "    # Save results to file each step in case of trouble\n",
    "    hindRH.to_csv(hindRHfile)\n",
    "    del surfaceRH         # Delete large dataframe and recover memory\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f670e3c",
   "metadata": {},
   "source": [
    "# Compute Heat Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d8b971",
   "metadata": {},
   "source": [
    "### Make dataframe of combined input data \n",
    "historical & forecast TAS & RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561aecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "allTAS = pd.concat([hindTAS, foreTAS])        # Append forecast to end of hindcast\n",
    "allRH = pd.concat([hindRH, foreRH])\n",
    "allTAS[\"mean\"] = allTAS.mean(axis=1, numeric_only=True)\n",
    "allRH[\"mean\"] = allRH.mean(axis=1, numeric_only=True)\n",
    "\n",
    "# Compute monthly ensemble mean of TAS & RH\n",
    "meanTAS_RH = pd.DataFrame()\n",
    "meanTAS_RH[\"TAS\"] = allTAS[\"mean\"].copy()\n",
    "meanTAS_RH[\"RH\"]  = allRH[\"mean\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d83372-1cb4-4310-956e-0622e560d6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanTAS_RH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0822d489",
   "metadata": {},
   "source": [
    "### Compute Heat Index for all years\n",
    "See [IncludeHelp](https://www.includehelp.com/python/pandas-apply-function-with-two-arguments-to-columns.aspx) for applying user function with multiple arguments (heatIndex) to each line of a Pandas DataFrame (meanTAS_RH).  N.B. Heat Index is in units of <sup>o</sup>F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571a3b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanTAS_RH['HI'] = meanTAS_RH.apply(lambda x: heatIndex(x['TAS'], x['RH']),axis=1)\n",
    "meanTAS_RH.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4d8adb",
   "metadata": {},
   "source": [
    "### Save monthly TAS-RH-HI results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c82f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanTAS_RH.to_csv(\"monthlyTAS-RH-HI.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1692b73c",
   "metadata": {},
   "source": [
    "## Save seasonal HI results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e62d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and save seasonal results.  Use convenient xarray tools, see\n",
    "# https://stackoverflow.com/questions/64976340/keeping-time-series-while-grouping-by-season-in-xarray\n",
    "# allHI = xr.DataArray.from_series(pd.concat([hindHI,foreHI]))  # Combined hind- & forecast HI as xarray\n",
    "allHI = meanTAS_RH['HI'].to_xarray()\n",
    "\n",
    "seasonalHIarray = allHI.resample(time='QS-DEC').mean(dim=\"time\")\n",
    "\n",
    "# Custom functions to determine season (using \"time.season\" gives unintended results for December)\n",
    "def isJJA(month):\n",
    "    # \"month\" is in NH summer\n",
    "    return (month >= 6) & (month <= 8)\n",
    "\n",
    "def isDJF(month):\n",
    "    # \"month\" is in NH winter.  Works for seasonal data...\n",
    "    return (month >= 11) & (month <= 12)\n",
    "\n",
    "summerHI = seasonalHIarray.sel(time=isJJA(seasonalHIarray['time.month']))\n",
    "pd.DataFrame(summerHI, index=summerHI[\"time.year\"]).to_csv(\"summerHI.csv\")\n",
    "# Winter historical results absurd for DFW, skip them\n",
    "winterHI = seasonalHIarray.sel(time=isDJF(seasonalHIarray['time.month']))\n",
    "pd.DataFrame(winterHI, index=winterHI[\"time.year\"]).to_csv(\"winterHI.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147c3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "endTime = time.time()\n",
    "runTime = endTime - startTime\n",
    "if (runTime < 60.0):\n",
    "    print(f\"Notebook run time = {runTime :5.2f} sec.\")\n",
    "else:\n",
    "    print(f\"Notebook run time = {(runTime/60) :5.2f} min.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde2bd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
